base_url: "http://localhost:11434/v1"  # Ollama endpoint or LM Studio
api_key: "none"
model: "artifish/llama3.2-uncensored"
